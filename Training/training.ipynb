{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Script for data cleaning**"
      ],
      "metadata": {
        "id": "O8BddO6yMgIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "directoryName = \"/content/drive/MyDrive/CCMT_FInal Dataset\";\n",
        "\n",
        "if os.path.exists(directoryName):\n",
        "    delete_corrupted_images(directoryName)\n",
        "    print(\"Operation complete.\")\n",
        "else:\n",
        "    print(\"Directory not found.\")\n",
        "\n",
        "def delete_corrupted_images(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            try:\n",
        "                # Attempt to open the image file\n",
        "                with Image.open(file_path) as img:\n",
        "                    pass  # Do nothing if the file is successfully opened\n",
        "            except (IOError, SyntaxError) as e:\n",
        "                print(f\"Corrupted file: {file_path}. Deleting...\")\n",
        "                os.remove(file_path)"
      ],
      "metadata": {
        "id": "hVDRZPIdLfK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TPU Support**"
      ],
      "metadata": {
        "id": "tOiRIijWgrUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-xla\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "tGlYJnEI4FlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "GMnhz2GO0Tn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for using tpu only\n",
        "DEVICE = xm.xla_device()"
      ],
      "metadata": {
        "id": "6kv3u9iD43zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Necessary** **Libraries**"
      ],
      "metadata": {
        "id": "lDuX1h-tgxYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image, ImageFile\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n"
      ],
      "metadata": {
        "id": "OLuVq-ag4Mya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yAWm67dvS4G",
        "outputId": "c63d305c-5015-4316-994b-bf6f35d79f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "M99A3jEZMyzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parameters Definition**"
      ],
      "metadata": {
        "id": "cbKuEA3xg7ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# defines the number of processes that loads the data, idealy set according to the number of the cores available in cpu\n",
        "NUM_WORKERS = min(4, os.cpu_count()) if DEVICE == \"cpu\" else 2\n",
        "BATCH_SIZE = 64;\n",
        "IMAGE_SIZE = 224\n",
        "PATH = \"/content/drive/MyDrive/AdversialDataset\";\n",
        "TRAIN_RATIO = 0.90"
      ],
      "metadata": {
        "id": "sFqkW_f8A9b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset**"
      ],
      "metadata": {
        "id": "nWJ0O1O4hL0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=PATH, transform=transform)"
      ],
      "metadata": {
        "id": "2IquKXPNK7-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(TRAIN_RATIO * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers = NUM_WORKERS)\n",
        "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers = NUM_WORKERS)\n"
      ],
      "metadata": {
        "id": "0XcViLrH1SLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(full_dataset.classes)"
      ],
      "metadata": {
        "id": "V2qgX_5J0jxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model : Resnet-50**\n",
        "\n"
      ],
      "metadata": {
        "id": "rHBI7gE5bF_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "3oK4_4_09OiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(resnet.parameters(), lr=0.0000001, momentum=0.009)"
      ],
      "metadata": {
        "id": "_jLwjXOz6ptr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading from Checkpoint**"
      ],
      "metadata": {
        "id": "XeFuMafThe0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading model states from a checkpoint\n",
        "resnet = resnet.to(DEVICE)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/cropsClassifierCheckpoints/checkpoint_11_epoch_lr=0.000001_2.pth',map_location=torch.device(DEVICE                                                                                                                      ));\n",
        "resnet.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "metadata": {
        "id": "lirAHSC6_MuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critValidationLoss = checkpoint[\"clsfValidationLoss\"]\n",
        "critTrainingLoss = checkpoint[\"critTrainingLoss\"]\n",
        "clsfValidationLoss = checkpoint[\"clsfValidationLoss\"]\n",
        "clsfTrainingLoss = checkpoint[\"clsfTrainingLoss\"]\n",
        "# clsfValidationBatch = checkpoint[\"clsfValidationBatch\"]\n",
        "epochIters   = checkpoint[\"epochIters\"]\n",
        "lossCriterionList = checkpoint[\"lossCriterionList\"]\n",
        "lossMisclassificationList = checkpoint[\"lossMisclassificationList\"]\n",
        "bIters = checkpoint[\"bIters\"]"
      ],
      "metadata": {
        "id": "yxWLf-IyTK8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "KyRf2m899POe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# these structures maintain the stats for whole epoch\n",
        "\n",
        "critValidationLoss = [];\n",
        "critTrainingLoss = [];\n",
        "\n",
        "# for misclassification stats\n",
        "\n",
        "clsfValidationLoss = [];\n",
        "clsfTrainingLoss = [];\n",
        "\n",
        "clsfValidationBatch = []\n",
        "\n",
        "epochIters = []\n",
        "print(f'device {DEVICE} , num_workers {NUM_WORKERS}' )"
      ],
      "metadata": {
        "id": "wM26MSklEztG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc9112c-121a-4d41-e20c-de02db5fd614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda , num_workers 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# these lists maintain the stats for a batch\n",
        "\n",
        "lossCriterionList = [0];\n",
        "lossMisclassificationList = [0]\n",
        "bIters = [0];"
      ],
      "metadata": {
        "id": "5DywD3MZ2c5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateMisclassificationPercentage(logits, labels):\n",
        "    \"\"\"\n",
        "    Calculate the percentage of misclassification given logits and truth labels.\n",
        "\n",
        "    Parameters:\n",
        "        logits (torch.Tensor): The predicted logits.\n",
        "        labels (torch.Tensor): The ground truth labels.\n",
        "\n",
        "    Returns:\n",
        "        float: The percentage of misclassification.\n",
        "    \"\"\"\n",
        "    _, predicted_indices = torch.max(logits, 1)\n",
        "    _, label_indices = torch.max(labels, 1)\n",
        "\n",
        "    correct = (predicted_indices == label_indices).sum().item()\n",
        "    total = label_indices.size(0)\n",
        "\n",
        "    return ((1 - (correct / total)) * 100)\n"
      ],
      "metadata": {
        "id": "Gr5-G37uqEuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/cropsClassifierCheckpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "ZCTRU0baZX_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loop for Training**"
      ],
      "metadata": {
        "id": "NWJmkBPjhuKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "resnet.to(DEVICE)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    currentTime = datetime.datetime.now()\n",
        "\n",
        "    timeStamp = currentTime.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "  # checkpoint for saving the model state for resue in case of interruptions\n",
        "    checkpoint = {\n",
        "      'epoch': epoch + 1,\n",
        "      'model_state_dict': resnet.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'critTrainingLoss': critTrainingLoss,\n",
        "      'clsfTrainingLoss': clsfTrainingLoss,\n",
        "      'critValidationLoss': critValidationLoss,\n",
        "      'clsfValidationLoss': clsfValidationLoss,\n",
        "      'epochIters': epochIters,\n",
        "      'bIters': bIters,\n",
        "      'lossCriterionList': lossCriterionList,\n",
        "      'lossMisclassificationList': lossMisclassificationList,\n",
        "      }\n",
        "\n",
        "    epochLoss = 0;\n",
        "    batchLoss = 0;\n",
        "\n",
        "    #switching to the training mode, gradients will be kept in record\n",
        "\n",
        "    resnet.train()\n",
        "\n",
        "    for batch , (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        # putting labels on accelator and converting them to one hot\n",
        "        labels = torch.eye(num_classes)[labels].to(DEVICE)\n",
        "        # [1,3,2,4]\n",
        "\n",
        "        #  [[0,1,0,0],[0,0,0,1],[0,0,1,0],[0,0,0,]]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # saving batch loss\n",
        "        batchLoss = loss.item()\n",
        "        epochLoss  = epochLoss + batchLoss;\n",
        "        lossCriterionList.append(batchLoss);\n",
        "        bIters.append(bIters[-1]+1);\n",
        "\n",
        "        #calculating the number of correctly classified examples\n",
        "        lossMisclassificationList.append(calculateMisclassificationPercentage(outputs,labels));\n",
        "\n",
        "        print(f'Criterion Loss : {batchLoss} Classification Loss : {lossMisclassificationList[-1]} ')\n",
        "\n",
        "\n",
        "    # plotting performance over entire epoch\n",
        "    plt.plot(bIters, lossCriterionList, color=\"green\", label=\"Criterion Loss\")\n",
        "    plt.plot(bIters, lossMisclassificationList, color=\"blue\", label=\"Classification Loss\")\n",
        "    plt.title(\"Epoch Loss\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/cropsClassifierCheckpoints/{timeStamp}_Epoch_Loss_epoch_{epoch}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    #calculating the average loss for the whole epoch\n",
        "    epochLoss = epochLoss/(batch+1);\n",
        "    # saving the criterion loss\n",
        "    critTrainingLoss.append(epochLoss);\n",
        "    #saving the average misclassification loss over whole batch for current epoch\n",
        "    clsfTrainingLoss.append(sum(lossMisclassificationList))\n",
        "    epochIters.append(epoch+1);\n",
        "\n",
        "    #switching to the evaluation mode no gradients graphs computed\n",
        "    resnet.eval()\n",
        "    with torch.no_grad():\n",
        "      # making this list empty after one epcoh\n",
        "        clsfValidationBatch=[]\n",
        "        evalLoss = 0;\n",
        "        for batchIdx ,(inputs, labels) in enumerate(val_loader):\n",
        "\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            labels = torch.eye(num_classes)[labels].to(DEVICE)\n",
        "            outputs = resnet(inputs)\n",
        "\n",
        "\n",
        "\n",
        "            # calculating the criterion loss can miscalssfication loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            evalLoss = evalLoss + loss.item();\n",
        "            clsfValidationBatch.append(calculateMisclassificationPercentage(outputs,labels))\n",
        "\n",
        "\n",
        "\n",
        "        evalLoss = evalLoss / (batchIdx+1)\n",
        "        critValidationLoss.append(evalLoss);\n",
        "        clsfValidationLoss.append(sum(clsfValidationBatch)/(batchIdx+1));\n",
        "\n",
        "\n",
        "        # shows how well model performed based on the criterion loss\n",
        "        plt.title(\"Criterion Loss\")\n",
        "        plt.plot(epochIters, critTrainingLoss, color=\"blue\", label=\"Training Loss\")\n",
        "        plt.plot(epochIters, critValidationLoss, color=\"red\", label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"/content/drive/MyDrive/cropsClassifierCheckpoints/{timeStamp}_CriterionLoss_epoch_{epoch}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # shows how well model performed based on the misclassfication\n",
        "        plt.title(\"Misclassification Loss\")\n",
        "        plt.plot(epochIters, clsfTrainingLoss, color=\"blue\", label=\"Training Loss\")\n",
        "        plt.plot(epochIters, clsfValidationLoss, color=\"red\", label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Mislcassifications\")\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"/content/drive/MyDrive/cropsClassifierCheckpoints/{timeStamp}_MisclassificationLoss_epoch_{epoch}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs},Training Loss {critTrainingLoss[-1]:.4f}, Validation Loss {critValidationLoss[-1]:.4f}\\nTraining Misclass {clsfTrainingLoss[-1]:.4f}, Validation Misclass {clsfValidationLoss[-1]:.4f}')\n",
        "\n",
        "    # saving checkpoint\n",
        "\n",
        "    checkpoint_filename = f'chkpnt_adv_{timeStamp}_{clsfValidationLoss[-1]}.pth'\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, checkpoint_filename)\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xjIRy3f5LDUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "Q1gNMIG-hzQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate_model(model, val_loader, num_classes, criterion, adversialFunc=None):\n",
        "    model.eval()\n",
        "    # Variables for storing results\n",
        "    clsfValidationBatch = []\n",
        "    evalLoss = 0\n",
        "\n",
        "    # Process validation data in batches with tqdm progress bar\n",
        "    for batchIdx, (inputs, labels) in tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation\"):\n",
        "\n",
        "\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = torch.eye(num_classes)[labels].to(DEVICE)\n",
        "\n",
        "        # Apply adverserial function if provided\n",
        "        if adversialFunc is not None:\n",
        "            outputs = adversialFunc(model,inputs,labels)\n",
        "        else:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        # Calculate the criterion loss (classification loss)\n",
        "        loss = criterion(outputs, labels)\n",
        "        evalLoss = evalLoss + loss.item()\n",
        "\n",
        "        # Calculate misclassification percentage\n",
        "        clsfValidationBatch.append(calculateMisclassificationPercentage(outputs, labels))\n",
        "\n",
        "    # Calculate average loss and misclassification percentage\n",
        "    evalLoss = evalLoss / (batchIdx + 1)\n",
        "    clsfValidationLoss = sum(clsfValidationBatch) / (batchIdx + 1)\n",
        "\n",
        "    return evalLoss, clsfValidationLoss\n"
      ],
      "metadata": {
        "id": "9Kwk7iNcxKz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evalLoss,misCls = evaluate_model(resnet,val_loader,22,criterion)"
      ],
      "metadata": {
        "id": "4z1V0_BPy39O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}